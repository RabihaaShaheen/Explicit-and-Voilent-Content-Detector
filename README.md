# Explicit-and-Voilent-Content-Detector


**What are Violent and non-violent videos?**
It is very broad topic to classify videos in violent and non-violent videos category. Therefore, it is almost impossible to get 100% accuracy in categorizing such videos because different actions can sometime be violent and sometimes be non-violent depending on the scenario in video. But under general definition such videos which causes aggression or provokes sexual feeling are categorized as violent videos.



**Challenges:**
•	Gender detection
•	Classification of objects
•	Occlusion
•	Background clutter
Human brain is capable of dealing with such challenges but our machine should be able to overcome these challenges.



**Motivation:**
                  All the violence detection issues are solved by this system. To recognize what is happening and to generate a notification of violent and nonviolent video and to reload the web page if the video is violent without creating any confusion. 
**Project Goal**
•	To foster a vicious recognition framework that can recognize and confine fierce scenes in recordings. 
•	To identify fierce scenes in recordings, a multimodality profound learning CNN will be prepared. The multimodality profound learning CNN engineering will be prepared and tried on video information in Vicious Scene Recognition Dataset 2014. Notwithstanding discovery, the rough scene discovery framework will actually want to decide the beginning and end outline for every scene and decide the level of viciousness that is available


**Processing**
•	Take URL of video playing
•	Detect violence in video
•	Block video
•	Being an open-source system
•	Being computationally efficient
•	Being highly robust
•	Ease of deployment in multiple modes which include standalone on individual desktop


**Software Specifications**
•	Flask
•	YouTube-dl
•	TensorFlow
•	Google Collab
•	Visual Studio Code
•	Chrome Extensions
•	Windows 10 


**Dataset**
Downloading the dataset from Kaggle and zipping it. Once the data is zipped its being extracted for detection in form of complete videos. 
The two python scripts used includes the following: 
•	train.py: Used as keras script which grabs the dataset videos we need for detection. 
•	plot.png: To get the accuracy/loss training history plot. 
•	predict_video.py: Loading the video from the zip and proceeding for classification. 



**Conclusion**
In this day and age humanity needs to work on using new teaching techniques and the internet to promote learning in children while also keeping them away from violent and inappropriate content. These young, impressionable minds should be exposed to various cultures, languages, science and many more so that they can take the world another step further to peace and harmony amongst all. We would encourage other computer scientists and programmers to create more software’s to safeguard the mental and social growth of the youth. We hope to inspire other to take this project further and rid the internet of inappropriate content in the most efficient manners possible.




